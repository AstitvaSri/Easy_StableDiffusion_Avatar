{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XU7NuMAA2drw"
      },
      "outputs": [],
      "source": [
        "# @markdown Initial Setup [ ~ 5 mins ] (Make sure you have atleast 5-6 GB of free space on your google drive for saving the checkpoints)\n",
        "\n",
        "\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader &> /dev/null\n",
        "!wget -q https://github.com/AstitvaSri/diffusers/raw/main/examples/dreambooth/train_dreambooth.py &> /dev/null\n",
        "!wget -q https://github.com/AstitvaSri/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py &> /dev/null\n",
        "%pip install -qq git+https://github.com/AstitvaSri/diffusers &> /dev/null\n",
        "%pip install -q -U --pre triton &> /dev/null\n",
        "%pip install -q accelerate==0.21.0 transformers ftfy bitsandbytes==0.35.0 gradio natsort safetensors xformers &> /dev/null\n",
        "\n",
        "!mkdir -p ~/.huggingface &> /dev/null\n",
        "HUGGINGFACE_TOKEN = \"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\"\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token &> /dev/null\n",
        "\n",
        "\n",
        "save_to_gdrive = True\n",
        "if save_to_gdrive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\"\n",
        "\n",
        "\n",
        "\n",
        "OUTPUT_DIR = \"dreambooth\"\n",
        "if save_to_gdrive:\n",
        "    OUTPUT_DIR = \"/content/drive/MyDrive/\" + OUTPUT_DIR\n",
        "else:\n",
        "    OUTPUT_DIR = \"/content/\" + OUTPUT_DIR\n",
        "\n",
        "print(f\"[*] Weights will be saved at {OUTPUT_DIR}\")\n",
        "\n",
        "!mkdir -p $OUTPUT_DIR\n",
        "\n",
        "# You can also add multiple concepts here. Try tweaking `--max_train_steps` accordingly.\n",
        "import os\n",
        "\n",
        "custom_keyword = \"ukj\"\n",
        "\n",
        "os.environ['SAMPLE_PROMPT'] = f'photo of {custom_keyword}' #to be used as default argument for '--save_sample_prompt' during training\n",
        "\n",
        "concepts_list = [\n",
        "    {\n",
        "        \"instance_prompt\":      \"photo of \" + custom_keyword,\n",
        "        \"class_prompt\":         \"photo of a person\",\n",
        "        \"instance_data_dir\":    \"/content/data/\" + custom_keyword,\n",
        "        \"class_data_dir\":       \"/content/data/person\"\n",
        "    },\n",
        "]\n",
        "\n",
        "# `class_data_dir` contains regularization images\n",
        "import json\n",
        "import os\n",
        "for c in concepts_list:\n",
        "    os.makedirs(c[\"instance_data_dir\"], exist_ok=True)\n",
        "\n",
        "with open(\"concepts_list.json\", \"w\") as f:\n",
        "    json.dump(concepts_list, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "32gYIDDR1aCp"
      },
      "outputs": [],
      "source": [
        "#@markdown Take 3-5 portrait images of your face like these: https://www.google.com/search?q=portrait+face&tbm=isch&ved=2ahUKEwjwgYCC6Zn-AhWExHMBHWR5Aa8Q2-cCegQIABAA&oq=portrait+face&gs_lcp=CgNpbWcQAzIFCAAQgAQyBQgAEIAEMgUIABCABDIFCAAQgAQyBQgAEIAEMgUIABCABDIFCAAQgAQyBQgAEIAEMgUIABCABDIFCAAQgAQ6BAgjECc6BwgAEIoFEENQ1gxY3hBgjRJoAHAAeACAAWSIAdUDkgEDNC4xmAEAoAEBqgELZ3dzLXdpei1pbWfAAQE&sclient=img&ei=lh8xZPDeJYSJz7sP5PKF-Ao&bih=973&biw=1920\n",
        "\n",
        "#@markdown Upload your images by running this cell.\n",
        "\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "for c in concepts_list:\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        dst_path = os.path.join(c['instance_data_dir'], filename)\n",
        "        shutil.move(filename, dst_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjcSXTp-u-Eg",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @markdown Process [ ~ 15 - 20 mins ] (If you want to see the progress, wait for 5 mins after running the cell and \"clear the output\" by clicking on the dotted button at the end)\n",
        "\n",
        "!accelerate launch train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --revision=\"fp16\" \\\n",
        "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "  --seed=1337 \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --train_text_encoder \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --use_8bit_adam \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --learning_rate=1e-6 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --num_class_images=25 \\\n",
        "  --sample_batch_size=2 \\\n",
        "  --max_train_steps=800 \\\n",
        "  --save_interval=10000 \\\n",
        "  --concepts_list=\"concepts_list.json\"\n",
        "\n",
        "WEIGHTS_DIR = \"\"\n",
        "if WEIGHTS_DIR == \"\":\n",
        "    from natsort import natsorted\n",
        "    from glob import glob\n",
        "    import os\n",
        "    WEIGHTS_DIR = natsorted(glob(OUTPUT_DIR + os.sep + \"*\"))[-1]\n",
        "# print(f\"[*] WEIGHTS_DIR={WEIGHTS_DIR}\")\n",
        "\n",
        "\n",
        "ckpt_path = WEIGHTS_DIR + \"/model.ckpt\"\n",
        "\n",
        "half_arg = \"\"\n",
        "fp16 = True \n",
        "if fp16:\n",
        "    half_arg = \"--half\"\n",
        "!python convert_diffusers_to_original_stable_diffusion.py --model_path $WEIGHTS_DIR  --checkpoint_path $ckpt_path $half_arg &> /dev/null\n",
        "\n",
        "# Reduce the `--save_interval` to lower than `--max_train_steps` to save weights from intermediate steps.\n",
        "# `--save_sample_prompt` can be same as `--instance_prompt` to generate intermediate samples (saved along with weights in samples directory).\n",
        "\n",
        "\n",
        "# Inference\n",
        "\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "from IPython.display import display\n",
        "\n",
        "model_path = WEIGHTS_DIR             # If you want to use previously trained model saved in gdrive, replace this with the full path of model in gdrive\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_path, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "g_cuda = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToNG4fd_dTbF"
      },
      "source": [
        "# Generate Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6xoHWSsbcS3",
        "scrolled": false,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown Harry Potter\n",
        "\n",
        "prompt = \"closeup portrait of ukj as a Harry Potter character, magical world, wands, robes, Hogwarts castle in the background, enchanted forest, detailed lighting, art by jim kay, charlie bowater, alphonse mucha, ronald brenzell, digital painting, concept art.\"\n",
        "negative_prompt = \"bad quality, low quality, bad anatomy, missing eyes\"\n",
        "num_samples = 4 \n",
        "guidance_scale = 7.5\n",
        "num_inference_steps = 24\n",
        "height = 512\n",
        "width = 512\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "for img in images:\n",
        "    display(img)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Clown\n",
        "\n",
        "prompt = \"Closeup portrait of ukj as a clown, highly detailed, surreal, expressionless face, bright colors, contrast lighting, abstract background, art by wlop, greg rutkowski, charlie bowater, magali villeneuve, alphonse mucha, cartoonish, comic book style.\"\n",
        "negative_prompt = \"bad quality, low quality, bad anatomy, missing eyes\"\n",
        "num_samples = 4 \n",
        "guidance_scale = 7.5\n",
        "num_inference_steps = 24\n",
        "height = 512\n",
        "width = 512\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "for img in images:\n",
        "    display(img)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DnO_axP1vqxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Astronaut\n",
        "\n",
        "prompt = \"closeup portrait of ukj as an astronaut, futuristic, highly detailed, ultra realistic, concept art, intricate textures, interstellar background, space travel, art by alphonse mucha, ryan kittleson, greg rutkowski, leesha hannigan, stephan martiniere, stanley artgerm lau.\"\n",
        "negative_prompt = \"bad quality, low quality, bad anatomy, missing eyes\"\n",
        "num_samples = 4 \n",
        "guidance_scale = 7.5\n",
        "num_inference_steps = 24\n",
        "height = 512\n",
        "width = 512\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "for img in images:\n",
        "    display(img)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "KJwE7kt7wIzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Superhero\n",
        "\n",
        "prompt = \"closeup portrait of ukj as a superhero, dynamic lighting, intense colors, detailed costume, artstation trending, art by alphonse mucha, greg rutkowski, ross tran, leesha hannigan, ignacio fernandez rios, kai carpenter, noir photorealism, film.\"\n",
        "negative_prompt = \"bad quality, low quality, bad anatomy, missing eyes\"\n",
        "num_samples = 4 \n",
        "guidance_scale = 7.5\n",
        "num_inference_steps = 24\n",
        "height = 512\n",
        "width = 512\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "for img in images:\n",
        "    display(img)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "d0DrP2SMwuBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Cyborg\n",
        "\n",
        "prompt = \"closeup portrait of ukj as a cyborg, mechanical parts, ultra realistic, concept art, intricate details, eerie, highly detailed, photorealistic, 8k, unreal engine. art by artgerm and greg rutkowski and charlie bowater and magali villeneuve and alphonse mucha, golden hour, cyberpunk, robotic, steampunk, neon colors, metallic textures.\"\n",
        "negative_prompt = \"bad quality, low quality, bad anatomy, missing eyes\"\n",
        "num_samples = 4 \n",
        "guidance_scale = 7.5\n",
        "num_inference_steps = 24\n",
        "height = 512\n",
        "width = 512\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "for img in images:\n",
        "    display(img)"
      ],
      "metadata": {
        "id": "o2925EnTxCIb",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Zombie\n",
        "\n",
        "prompt = \"closeup portrait of ukj as a zombie, decaying skin and clothing, dark and eerie, highly detailed, photorealistic, 8k, ultra realistic, horror style, art by greg rutkowski, charlie bowater, and magali villeneuve.\"\n",
        "negative_prompt = \"bad quality, low quality, bad anatomy, missing eyes\"\n",
        "num_samples = 4 \n",
        "guidance_scale = 7.5\n",
        "num_inference_steps = 24\n",
        "height = 512\n",
        "width = 512\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "for img in images:\n",
        "    display(img)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "bNeRbGF9xODL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***You can run the cell below and provide you own prompts top generate a desired output.***\n",
        "\n",
        "e.g. Prompt: a photo of ukj eating a pizza, 4k high quality, perfect facial features.\n",
        "\n",
        "[ Note: **'ukj'** is an alias token which is important to put within the prompt ]\n",
        "\n",
        "You can also click on the link to open Gradio's image generation workspace in a new tab."
      ],
      "metadata": {
        "id": "pzBJZ8_RxmTT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WMCqQ5Tcdsm2"
      },
      "outputs": [],
      "source": [
        "#@markdown Run Gradio UI for generating images.\n",
        "import gradio as gr\n",
        "\n",
        "def inference(prompt, negative_prompt, num_samples, height=512, width=512, num_inference_steps=50, guidance_scale=7.5):\n",
        "    with torch.autocast(\"cuda\"), torch.inference_mode():\n",
        "        return pipe(\n",
        "                prompt, height=int(height), width=int(width),\n",
        "                negative_prompt=negative_prompt,\n",
        "                num_images_per_prompt=int(num_samples),\n",
        "                num_inference_steps=int(num_inference_steps), guidance_scale=guidance_scale,\n",
        "                generator=g_cuda\n",
        "            ).images\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            prompt = gr.Textbox(label=\"Prompt\", value=\"photo of ukj eating a donut.\")\n",
        "            negative_prompt = gr.Textbox(label=\"Negative Prompt\", value=\"bad face, low quality, bad quality, missing eyes, missing nose, bad anaotmy, missing fingers\")\n",
        "            run = gr.Button(value=\"Generate\")\n",
        "            with gr.Row():\n",
        "                num_samples = gr.Number(label=\"Number of Samples\", value=4)\n",
        "                guidance_scale = gr.Number(label=\"Guidance Scale\", value=7.5)\n",
        "            with gr.Row():\n",
        "                height = gr.Number(label=\"Height\", value=512)\n",
        "                width = gr.Number(label=\"Width\", value=512)\n",
        "            num_inference_steps = gr.Slider(label=\"Steps\", value=24)\n",
        "        with gr.Column():\n",
        "            gallery = gr.Gallery()\n",
        "\n",
        "    run.click(inference, inputs=[prompt, negative_prompt, num_samples, height, width, num_inference_steps, guidance_scale], outputs=gallery)\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXgi8HM4c-DA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown Free runtime memory (running this will delete all the data and environment variables and you have to start from scratch)\n",
        "exit()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
